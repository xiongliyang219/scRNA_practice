{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 4.984695 , 4.984695 , ..., 0.       , 4.984695 ,\n",
       "        0.       ],\n",
       "       [6.540169 , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [5.5964065, 0.       , 0.       , ..., 0.       , 5.5964065,\n",
       "        0.       ],\n",
       "       [6.0348916, 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [4.9338408, 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the scanpy object which was saved from scRNA_practice.ipynb\n",
    "save_file = '/Users/xly/Desktop/study/python/adata_combat.h5ad'\n",
    "adata_combat = sc.read_h5ad(save_file)\n",
    "\n",
    "# Use log normalzied raw data as input to VAE\n",
    "# Note that as a demo, the cells are already assigned clusters in scRNA_practice.ipynb. \n",
    "# In real applications, the clusters are not known when VAE is used for dimentionality reduction\n",
    "adata_pp = adata_combat.copy()\n",
    "adata_pp.X = adata_combat.layers[\"counts\"] \n",
    "sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6)\n",
    "sc.pp.log1p(adata_pp)\n",
    "\n",
    "X = adata_pp.X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = 59337.2148\n",
      "Start of epoch 1\n",
      "step 0: mean loss = 38969.3398\n",
      "Start of epoch 2\n",
      "step 0: mean loss = 38154.1484\n",
      "Start of epoch 3\n",
      "step 0: mean loss = 37656.4102\n",
      "Start of epoch 4\n",
      "step 0: mean loss = 37310.5156\n",
      "Start of epoch 5\n",
      "step 0: mean loss = 37056.2070\n",
      "Start of epoch 6\n",
      "step 0: mean loss = 36866.9062\n",
      "Start of epoch 7\n",
      "step 0: mean loss = 36721.1680\n",
      "Start of epoch 8\n",
      "step 0: mean loss = 36600.0469\n",
      "Start of epoch 9\n",
      "step 0: mean loss = 36498.6992\n",
      "Start of epoch 10\n",
      "step 0: mean loss = 36417.0352\n",
      "Start of epoch 11\n",
      "step 0: mean loss = 36338.0273\n",
      "Start of epoch 12\n",
      "step 0: mean loss = 36263.9961\n",
      "Start of epoch 13\n",
      "step 0: mean loss = 36195.2578\n",
      "Start of epoch 14\n",
      "step 0: mean loss = 36135.1133\n",
      "Start of epoch 15\n",
      "step 0: mean loss = 36079.6641\n",
      "Start of epoch 16\n",
      "step 0: mean loss = 36022.7930\n",
      "Start of epoch 17\n",
      "step 0: mean loss = 35969.9922\n",
      "Start of epoch 18\n",
      "step 0: mean loss = 35922.4219\n",
      "Start of epoch 19\n",
      "step 0: mean loss = 35875.9258\n",
      "Start of epoch 20\n",
      "step 0: mean loss = 35831.9414\n",
      "Start of epoch 21\n",
      "step 0: mean loss = 35790.6992\n",
      "Start of epoch 22\n",
      "step 0: mean loss = 35752.0156\n",
      "Start of epoch 23\n",
      "step 0: mean loss = 35714.1602\n",
      "Start of epoch 24\n",
      "step 0: mean loss = 35679.9805\n",
      "Start of epoch 25\n",
      "step 0: mean loss = 35644.5039\n",
      "Start of epoch 26\n",
      "step 0: mean loss = 35613.5977\n",
      "Start of epoch 27\n",
      "step 0: mean loss = 35583.7773\n",
      "Start of epoch 28\n",
      "step 0: mean loss = 35553.7891\n",
      "Start of epoch 29\n",
      "step 0: mean loss = 35522.5938\n",
      "Start of epoch 30\n",
      "step 0: mean loss = 35495.2930\n",
      "Start of epoch 31\n",
      "step 0: mean loss = 35468.8164\n",
      "Start of epoch 32\n",
      "step 0: mean loss = 35444.1836\n",
      "Start of epoch 33\n",
      "step 0: mean loss = 35417.6719\n",
      "Start of epoch 34\n",
      "step 0: mean loss = 35393.9219\n",
      "Start of epoch 35\n",
      "step 0: mean loss = 35367.9961\n",
      "Start of epoch 36\n",
      "step 0: mean loss = 35340.5469\n",
      "Start of epoch 37\n",
      "step 0: mean loss = 35315.1328\n",
      "Start of epoch 38\n",
      "step 0: mean loss = 35290.8789\n",
      "Start of epoch 39\n",
      "step 0: mean loss = 35267.3008\n",
      "Start of epoch 40\n",
      "step 0: mean loss = 35245.1562\n",
      "Start of epoch 41\n",
      "step 0: mean loss = 35223.6406\n",
      "Start of epoch 42\n",
      "step 0: mean loss = 35202.0859\n",
      "Start of epoch 43\n",
      "step 0: mean loss = 35181.6875\n",
      "Start of epoch 44\n",
      "step 0: mean loss = 35161.8477\n",
      "Start of epoch 45\n",
      "step 0: mean loss = 35141.7344\n",
      "Start of epoch 46\n",
      "step 0: mean loss = 35123.2734\n",
      "Start of epoch 47\n",
      "step 0: mean loss = 35104.3633\n",
      "Start of epoch 48\n",
      "step 0: mean loss = 35087.0469\n",
      "Start of epoch 49\n",
      "step 0: mean loss = 35070.9297\n",
      "Start of epoch 50\n",
      "step 0: mean loss = 35054.9258\n",
      "Start of epoch 51\n",
      "step 0: mean loss = 35039.3711\n",
      "Start of epoch 52\n",
      "step 0: mean loss = 35023.3984\n",
      "Start of epoch 53\n",
      "step 0: mean loss = 35008.9219\n",
      "Start of epoch 54\n",
      "step 0: mean loss = 34994.1328\n",
      "Start of epoch 55\n",
      "step 0: mean loss = 34978.9922\n",
      "Start of epoch 56\n",
      "step 0: mean loss = 34964.0195\n",
      "Start of epoch 57\n",
      "step 0: mean loss = 34949.3867\n",
      "Start of epoch 58\n",
      "step 0: mean loss = 34934.9844\n",
      "Start of epoch 59\n",
      "step 0: mean loss = 34920.3555\n",
      "Start of epoch 60\n",
      "step 0: mean loss = 34906.6289\n",
      "Start of epoch 61\n",
      "step 0: mean loss = 34892.6641\n",
      "Start of epoch 62\n",
      "step 0: mean loss = 34879.7383\n",
      "Start of epoch 63\n",
      "step 0: mean loss = 34867.3633\n",
      "Start of epoch 64\n",
      "step 0: mean loss = 34855.3594\n",
      "Start of epoch 65\n",
      "step 0: mean loss = 34843.2031\n",
      "Start of epoch 66\n",
      "step 0: mean loss = 34832.2461\n",
      "Start of epoch 67\n",
      "step 0: mean loss = 34821.5859\n",
      "Start of epoch 68\n",
      "step 0: mean loss = 34810.0898\n",
      "Start of epoch 69\n",
      "step 0: mean loss = 34798.4648\n",
      "Start of epoch 70\n",
      "step 0: mean loss = 34787.3359\n",
      "Start of epoch 71\n",
      "step 0: mean loss = 34776.3438\n",
      "Start of epoch 72\n",
      "step 0: mean loss = 34765.3242\n",
      "Start of epoch 73\n",
      "step 0: mean loss = 34754.4648\n",
      "Start of epoch 74\n",
      "step 0: mean loss = 34743.4883\n",
      "Start of epoch 75\n",
      "step 0: mean loss = 34732.1445\n",
      "Start of epoch 76\n",
      "step 0: mean loss = 34721.8008\n",
      "Start of epoch 77\n",
      "step 0: mean loss = 34711.3281\n",
      "Start of epoch 78\n",
      "step 0: mean loss = 34700.7305\n",
      "Start of epoch 79\n",
      "step 0: mean loss = 34690.4180\n",
      "Start of epoch 80\n",
      "step 0: mean loss = 34680.6484\n",
      "Start of epoch 81\n",
      "step 0: mean loss = 34671.0273\n",
      "Start of epoch 82\n",
      "step 0: mean loss = 34661.2812\n",
      "Start of epoch 83\n",
      "step 0: mean loss = 34651.8867\n",
      "Start of epoch 84\n",
      "step 0: mean loss = 34642.3594\n",
      "Start of epoch 85\n",
      "step 0: mean loss = 34632.7695\n",
      "Start of epoch 86\n",
      "step 0: mean loss = 34624.1289\n",
      "Start of epoch 87\n",
      "step 0: mean loss = 34615.3203\n",
      "Start of epoch 88\n",
      "step 0: mean loss = 34606.3359\n",
      "Start of epoch 89\n",
      "step 0: mean loss = 34597.9336\n",
      "Start of epoch 90\n",
      "step 0: mean loss = 34589.2773\n",
      "Start of epoch 91\n",
      "step 0: mean loss = 34581.3008\n",
      "Start of epoch 92\n",
      "step 0: mean loss = 34573.1289\n",
      "Start of epoch 93\n",
      "step 0: mean loss = 34564.8711\n",
      "Start of epoch 94\n",
      "step 0: mean loss = 34556.9492\n",
      "Start of epoch 95\n",
      "step 0: mean loss = 34549.1680\n",
      "Start of epoch 96\n",
      "step 0: mean loss = 34541.2227\n",
      "Start of epoch 97\n",
      "step 0: mean loss = 34533.5312\n",
      "Start of epoch 98\n",
      "step 0: mean loss = 34526.4844\n",
      "Start of epoch 99\n",
      "step 0: mean loss = 34518.9609\n",
      "Start of epoch 100\n",
      "step 0: mean loss = 34511.6211\n",
      "Start of epoch 101\n",
      "step 0: mean loss = 34504.1016\n",
      "Start of epoch 102\n",
      "step 0: mean loss = 34496.6992\n"
     ]
    }
   ],
   "source": [
    "orig_dim = X.shape[1]\n",
    "vae = VAE(orig_dim)\n",
    "\n",
    "train_step(200, vae, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without the following 2 lines, error can occur\n",
    "inputs = tf.keras.Input(shape=X.shape)\n",
    "vae.call(inputs)\n",
    "\n",
    "layer_names=[layer.name for layer in vae.layers]\n",
    "latent_layer = K.function(inputs=[vae.layers[0].input], outputs=[vae.get_layer(layer_names[0]).output])\n",
    "latent = latent_layer([X])\n",
    "\n",
    "x_encoded = np.array(latent[0][0][2])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "for i, obs in zip([0, 1, 2], ['region', 'sample', 'louvain_r0.65']):\n",
    "    le.fit(list(adata_combat.obs[obs]))\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    \n",
    "    color = le.transform(adata_combat.obs[obs])    \n",
    "    im = axes[i].scatter(x_encoded[:, 0], x_encoded[:, 1], c=color, marker='o', s=10)\n",
    "    axes[i].set_xlabel('z [0]', fontsize='16')\n",
    "    axes[i].set_ylabel('z [1]', fontsize='16')\n",
    "    axes[i].set_title(obs, fontsize='16')\n",
    "    cb = plt.colorbar(im, ax=axes[i])\n",
    "    loc = np.arange(max(color) + 1)\n",
    "    cb.set_ticks(loc)\n",
    "    cb.set_ticklabels(list(le_name_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
